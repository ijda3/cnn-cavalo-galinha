{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cavalo_ou_galinha.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5uSaG_Ch2cj"
      },
      "source": [
        "!pip install -q keras\n",
        "!pip install -q tensorflow\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQTPRHWzHzFP"
      },
      "source": [
        "# Setup do dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ck4SZoRlId4m"
      },
      "source": [
        "### Clonando o dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75nkW3vepZU1"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "from zipfile import ZipFile\n",
        "from urllib.request import urlopen\n",
        "\n",
        "if os.path.exists('dataset'):\n",
        "  shutil.rmtree('dataset')\n",
        "\n",
        "if os.path.exists('sample_data'):\n",
        "  shutil.rmtree('sample_data')\n",
        "\n",
        "if not os.path.isfile('dataset.zip'):\n",
        "  zipresp = urlopen('https://github.com/ijda3/cnn-cavalo-galinha/raw/main/dataset.zip')\n",
        "  tempzip = open(\"dataset.zip\", \"wb\")\n",
        "  tempzip.write(zipresp.read())\n",
        "  tempzip.close()\n",
        "\n",
        "zf = ZipFile(\"dataset.zip\")\n",
        "zf.extractall(path = './')\n",
        "zf.close()\n",
        "\n",
        "if os.path.exists('__MACOSX'):\n",
        "  shutil.rmtree('__MACOSX')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8OiZRIVIu73"
      },
      "source": [
        "### Separando arquivos de treino e teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X76uXcmp1_nF"
      },
      "source": [
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "dataset_basedir = 'dataset'\n",
        "\n",
        "if os.path.exists('training_set'):\n",
        "  shutil.rmtree('training_set')\n",
        "\n",
        "if os.path.exists('test_set'):\n",
        "  shutil.rmtree('test_set')\n",
        "\n",
        "def copy_files(files, dest, dir):\n",
        "  for file in files:\n",
        "    if not os.path.exists(dest):\n",
        "      os.mkdir(dest)\n",
        "      \n",
        "    if not os.path.exists(dest + '/' + dir):\n",
        "      os.mkdir(dest + '/' + dir)\n",
        "      \n",
        "    shutil.copy(dataset_basedir + '/' + dir + '/' + file, dest + '/' + dir + '/' + file)\n",
        "\n",
        "for dir in ['cavalo', 'galinha']:\n",
        "  files = os.listdir(dataset_basedir + '/' + dir)\n",
        "\n",
        "  train, valid = train_test_split(files, train_size=0.8)\n",
        "\n",
        "  copy_files(train, 'training_set', dir)\n",
        "  copy_files(valid, 'test_set', dir)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDfkEnQ7hwvP"
      },
      "source": [
        "#Construção da CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2GRGLJuhiJR"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "from keras.preprocessing import image"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56YNorQshop5"
      },
      "source": [
        "classificador = Sequential()\n",
        "classificador.add(Conv2D(32, (3,3), input_shape = (64, 64, 3), activation = 'relu'))\n",
        "classificador.add(BatchNormalization())\n",
        "classificador.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "classificador.add(Conv2D(32, (3,3), input_shape = (64, 64, 3), activation = 'relu'))\n",
        "classificador.add(BatchNormalization())\n",
        "classificador.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "classificador.add(Flatten())\n",
        "\n",
        "classificador.add(Dense(units = 256, activation = 'relu'))\n",
        "classificador.add(Dropout(0.1))\n",
        "classificador.add(Dense(units = 256, activation = 'sigmoid'))\n",
        "classificador.add(Dropout(0.1))\n",
        "classificador.add(Dense(units = 1, activation = 'sigmoid'))\n",
        "\n",
        "classificador.compile(optimizer = 'adam', loss = 'binary_crossentropy',\n",
        "                      metrics = ['accuracy'])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeeXvYDfhzov"
      },
      "source": [
        "#Treinamento da Rede"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLmoT73dhtA-",
        "outputId": "d8fb5ea3-2b74-4d5e-a51a-1039d2ba2651"
      },
      "source": [
        "gerador_treinamento = ImageDataGenerator(rescale = 1./255,\n",
        "                                         rotation_range = 7,\n",
        "                                         horizontal_flip = True,\n",
        "                                         shear_range = 0.2,\n",
        "                                         height_shift_range = 0.07,\n",
        "                                         zoom_range = 0.2)\n",
        "gerador_teste = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "base_treinamento = gerador_treinamento.flow_from_directory('training_set',\n",
        "                                                           target_size = (64, 64),\n",
        "                                                           batch_size = 32,\n",
        "                                                           class_mode = 'binary')\n",
        "base_teste = gerador_teste.flow_from_directory('test_set',\n",
        "                                               target_size = (64, 64),\n",
        "                                               batch_size = 32,\n",
        "                                               class_mode = 'binary')\n",
        "classificador.fit(base_treinamento, steps_per_epoch = base_treinamento.samples / 32,\n",
        "                            epochs = 10, validation_data = base_teste,\n",
        "                            validation_steps = base_teste.samples / 32)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4567 images belonging to 2 classes.\n",
            "Found 1144 images belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "142/142 [==============================] - 16s 114ms/step - loss: 0.0664 - accuracy: 0.9739 - val_loss: 1.1497 - val_accuracy: 0.7351\n",
            "Epoch 2/10\n",
            "142/142 [==============================] - 16s 113ms/step - loss: 0.0779 - accuracy: 0.9698 - val_loss: 0.3449 - val_accuracy: 0.8890\n",
            "Epoch 3/10\n",
            "142/142 [==============================] - 16s 111ms/step - loss: 0.0809 - accuracy: 0.9674 - val_loss: 0.2542 - val_accuracy: 0.9073\n",
            "Epoch 4/10\n",
            "142/142 [==============================] - 16s 112ms/step - loss: 0.0588 - accuracy: 0.9759 - val_loss: 0.2125 - val_accuracy: 0.9344\n",
            "Epoch 5/10\n",
            "142/142 [==============================] - 16s 113ms/step - loss: 0.0555 - accuracy: 0.9755 - val_loss: 0.5030 - val_accuracy: 0.8698\n",
            "Epoch 6/10\n",
            "142/142 [==============================] - 16s 112ms/step - loss: 0.0508 - accuracy: 0.9825 - val_loss: 0.3320 - val_accuracy: 0.9003\n",
            "Epoch 7/10\n",
            "142/142 [==============================] - 16s 112ms/step - loss: 0.0493 - accuracy: 0.9812 - val_loss: 0.2809 - val_accuracy: 0.9240\n",
            "Epoch 8/10\n",
            "142/142 [==============================] - 16s 110ms/step - loss: 0.0515 - accuracy: 0.9810 - val_loss: 0.3615 - val_accuracy: 0.8916\n",
            "Epoch 9/10\n",
            "142/142 [==============================] - 16s 112ms/step - loss: 0.0578 - accuracy: 0.9772 - val_loss: 0.2248 - val_accuracy: 0.9309\n",
            "Epoch 10/10\n",
            "142/142 [==============================] - 16s 113ms/step - loss: 0.0489 - accuracy: 0.9805 - val_loss: 0.2410 - val_accuracy: 0.9178\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff082503990>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-pZbnpaLfij"
      },
      "source": [
        "# Validação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKXeJTfhLnLb"
      },
      "source": [
        "### Separação do dataset usando o modelo treinado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoRl-WZnstc4"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "if os.path.exists('dataset_result'):\n",
        "  shutil.rmtree('dataset_result')\n",
        "\n",
        "os.mkdir('dataset_result')\n",
        "os.mkdir('dataset_result/cavalo')\n",
        "os.mkdir('dataset_result/galinha')\n",
        "\n",
        "images = []\n",
        "\n",
        "root = 'dataset'\n",
        "\n",
        "for path, subdirs, files in os.walk(root):\n",
        "    for name in files:\n",
        "        images.append(os.path.join(path, name))\n",
        "\n",
        "for file in images:\n",
        "  source = file\n",
        "  file = os.path.basename(source)\n",
        "\n",
        "  if file[0] == '.':\n",
        "    continue\n",
        "\n",
        "  imagem_teste = image.load_img(source, target_size = (64,64))\n",
        "\n",
        "  imagem_teste = image.img_to_array(imagem_teste)\n",
        "  imagem_teste/=255\n",
        "  imagem_teste = np.expand_dims(imagem_teste, axis=0)\n",
        "\n",
        "  previsao = classificador.predict(imagem_teste)\n",
        "\n",
        "  if previsao > 0.5:\n",
        "    dest = 'dataset_result/galinha/' + file\n",
        "  else:\n",
        "    dest = 'dataset_result/cavalo/' + file\n",
        "\n",
        "  shutil.copy(source, dest)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hf8GHX0LN4ox"
      },
      "source": [
        "### Computando o resultado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ah5maPpAN34I",
        "outputId": "bc8550b8-d97d-4ebd-b2da-bfd32234b180"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "\n",
        "files_by_category = {\n",
        "    'galinha': [],\n",
        "    'cavalo': []\n",
        "}\n",
        "\n",
        "stats = {\n",
        "    'galinha': {\n",
        "        'total': 0,\n",
        "        'acertos': 0,\n",
        "        'erros': 0,\n",
        "        'acuracia': 0\n",
        "    },\n",
        "    'cavalo': {\n",
        "        'total': 0,\n",
        "        'acertos': 0,\n",
        "        'erros': 0,\n",
        "        'acuracia': 0\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "if os.path.exists('dataset_result_errado'):\n",
        "  shutil.rmtree('dataset_result_errado')\n",
        "\n",
        "os.mkdir('dataset_result_errado')\n",
        "os.mkdir('dataset_result_errado/galinha')\n",
        "os.mkdir('dataset_result_errado/cavalo')\n",
        "\n",
        "for path, subdirs, files in os.walk('dataset'):\n",
        "    for name in files:\n",
        "        if path.find('galinha') >= 0:\n",
        "            files_by_category['galinha'].append(name)\n",
        "        elif path.find('cavalo') >= 0:\n",
        "            files_by_category['cavalo'].append(name)\n",
        "\n",
        "stats['galinha']['total'] = len(files_by_category['galinha'])\n",
        "stats['cavalo']['total'] = len(files_by_category['cavalo'])\n",
        "\n",
        "for path, subdirs, files in os.walk('dataset_result/'):\n",
        "    for name in files:\n",
        "        file = os.path.join(path, name)\n",
        "\n",
        "        if path.find('galinha') >= 0:\n",
        "            if name in files_by_category['galinha']:\n",
        "                stats['galinha']['acertos'] += 1\n",
        "            else:\n",
        "                stats['cavalo']['erros'] += 1\n",
        "                shutil.copy(\n",
        "                    file, 'dataset_result_errado/galinha/' + name)\n",
        "\n",
        "        elif path.find('cavalo') >= 0:\n",
        "            if name in files_by_category['cavalo']:\n",
        "                stats['cavalo']['acertos'] += 1\n",
        "            else:\n",
        "                stats['galinha']['erros'] += 1\n",
        "                shutil.copy(\n",
        "                    file, 'dataset_result_errado/cavalo/' + name)\n",
        "\n",
        "\n",
        "stats['galinha']['acuracia'] = round(\n",
        "    stats['galinha']['acertos'] / stats['galinha']['total'], 4)\n",
        "stats['cavalo']['acuracia'] = round(\n",
        "    stats['cavalo']['acertos'] / stats['cavalo']['total'], 4)\n",
        "\n",
        "print(pd.DataFrame(stats).T)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          total  acertos  erros  acuracia\n",
            "galinha  3096.0   3001.0   94.0    0.9693\n",
            "cavalo   2617.0   2511.0  105.0    0.9595\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnVzvd2pOWEM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "be92b8da-5a97-47f5-fb23-2244d04d8f52"
      },
      "source": [
        "shutil.make_archive('dataset_result_errado', 'zip', 'dataset_result_errado')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/dataset_result_errado.zip'"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}